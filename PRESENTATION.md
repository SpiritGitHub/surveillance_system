# ÔøΩ Pr√©sentation Compl√®te : Syst√®me de Surveillance Intelligent Multi-Cam√©ras

Ce document est votre **script ma√Ætre**. Il couvre le projet de A √† Z, avec des d√©tails techniques pour r√©pondre aux questions pointues.

---

## 1. Introduction & Contexte üåç

### Le Probl√®me

La vid√©osurveillance actuelle g√©n√®re plus de donn√©es qu'un humain ne peut en traiter.

- **Surcharge cognitive** : Un op√©rateur rate 95% des √©v√©nements apr√®s 20 minutes.
- **Donn√©es non structur√©es** : Une vid√©o est une suite de pixels, pas une base de donn√©es interrogeable.
- **Fragmentation** : Les cam√©ras ne "se parlent" pas. Suivre un suspect d'une pi√®ce √† l'autre est manuel et fastidieux.

### Notre Solution

Un pipeline de **Vision par Ordinateur (Computer Vision)** qui transforme le flux vid√©o en **donn√©es structur√©es et exploitables**.

- **Automatis√©** : D√©tection et alerte sans intervention.
- **Unifi√©** : R√©-identification des personnes √† travers le r√©seau de cam√©ras.
- **Analytique** : G√©n√©ration de statistiques (flux, temps de pr√©sence).

---

## 2. M√©thodologie & Architecture üèóÔ∏è

Notre approche est modulaire, bas√©e sur un pipeline de traitement s√©quentiel.

### Phase 1 : Acquisition & Synchronisation

- **Source** : R√©seau de cam√©ras h√©t√©rog√®nes (smartphones, webcams).
- **D√©fi** : Les cam√©ras ne d√©marrent pas en m√™me temps.
- **Solution** : Synchronisation post-traitement via `camera_offsets_durree.json`. On aligne temporellement toutes les trajectoires sur une r√©f√©rence commune ($t_{sync} = t_{video} + \Delta_{offset}$).

### Phase 2 : D√©tection d'Objets (L'≈íil)

- **Technologie** : **YOLOv8** (You Only Look Once, version 8).
- **Pourquoi ?** : Compromis id√©al entre vitesse (temps r√©el) et pr√©cision.
- **Fonctionnement** : R√©seau de neurones convolutif (CNN) qui divise l'image en grille et pr√©dit simultan√©ment les bo√Ætes englobantes (bounding boxes) et les classes.
- **Classes** : Personnes, V√©hicules (voiture, moto, bus, camion), Bagages.

### Phase 3 : Suivi Multi-Cibles (La M√©moire)

- **Technologie** : **DeepSORT** (Simple Online and Realtime Tracking with a Deep Association Metric).
- **Probl√®me r√©solu** : YOLO d√©tecte ind√©pendamment sur chaque frame. Il ne sait pas que la personne en frame $t$ est la m√™me qu'en $t+1$.
- **Fonctionnement** :
  1.  **Filtre de Kalman** : Predit la position future de l'objet (vitesse, direction).
  2.  **Algorithme Hongrois** : Associe les nouvelles d√©tections aux pr√©dictions (qui est le plus proche de qui ?).
  3.  **M√©trique d'apparence** : Utilise un petit r√©seau de neurones pour v√©rifier que l'apparence visuelle correspond (√©vite de confondre deux personnes qui se croisent).

### Phase 4 : Analyse S√©mantique (Le Gardien)

- **Zones** : D√©finies par des polygones (`shapely`).
- **Logique** : Test d'inclusion g√©om√©trique ($Point \in Polygone$).
- **Temporel** : Une alerte n'est lev√©e que si $Temps_{presence} > Seuil$ (√©vite les faux positifs sur un passage rapide).

### Phase 5 : R√©-identification Multi-Cam√©ras (Le Cerveau)

- **Objectif** : Lier les trajectoires de la Cam√©ra A et de la Cam√©ra B.
- **Technologie** : **ResNet50** (R√©seau R√©siduel √† 50 couches).
- **Processus** :
  1.  Extraction de l'image de la personne (crop).
  2.  Passage dans ResNet50 (sans la couche de classification finale).
  3.  Sortie : Un vecteur de 2048 nombres (**Embedding**). Ce vecteur est la "signature num√©rique" de l'apparence de la personne.
  4.  **Matching** : Calcul de la **Distance Cosinus** entre les vecteurs.
      - Si $Distance < 0.3 \Rightarrow$ M√™me personne.
      - Si $Distance > 0.3 \Rightarrow$ Personnes diff√©rentes.

---

## 3. D√©tails Techniques pour les Questions (Q&A) üß†

Soyez pr√™t √† r√©pondre √† ces questions techniques !

**Q: Pourquoi YOLOv8 et pas Faster R-CNN ou SSD ?**
**R:** YOLOv8 est un mod√®le "one-stage" (une seule passe). Il est beaucoup plus rapide que Faster R-CNN (two-stage) tout en gardant une pr√©cision comparable pour notre cas d'usage. C'est crucial pour traiter de la vid√©o.

**Q: Comment g√©rez-vous les occlusions (quand une personne passe derri√®re un poteau) ?**
**R:** C'est le r√¥le du **Filtre de Kalman** dans DeepSORT. M√™me si la d√©tection √©choue pendant quelques frames, le filtre continue de pr√©dire la position. Si la personne r√©appara√Æt l√† o√π on l'attendait, l'ID est conserv√©. On a configur√© un `max_age` de 30 frames (1 seconde) pour garder la m√©moire.

**Q: Qu'est-ce que l'IoU (Intersection over Union) ?**
**R:** C'est une m√©trique pour mesurer la pr√©cision d'une d√©tection. C'est le rapport entre l'aire de l'intersection (zone commune) et l'aire de l'union des deux bo√Ætes (pr√©dite vs r√©elle). DeepSORT l'utilise pour associer les bo√Ætes.

**Q: Pourquoi la distance Cosinus pour le Re-ID ?**
**R:** Les embeddings sont des vecteurs dans un espace √† haute dimension. La distance euclidienne (r√®gle) est moins efficace en haute dimension. La distance cosinus mesure l'angle entre les vecteurs, ce qui est plus robuste aux variations d'intensit√© lumineuse ou de contraste.

**Q: Comment avez-vous g√©r√© les diff√©rences de luminosit√© entre les cam√©ras ?**
**R:** C'est un d√©fi. Le mod√®le ResNet50 est pr√©-entra√Æn√© sur ImageNet (√©norme base de donn√©es) et a appris √† √™tre relativement invariant √† l'√©clairage. De plus, nous normalisons les vecteurs avant la comparaison.

---

## 4. R√©sultats & D√©monstration ÔøΩ

### Ce que nous avons obtenu

- Un syst√®me capable de traiter X vid√©os en parall√®le.
- G√©n√©ration automatique de fichiers JSON contenant toutes les m√©tadonn√©es.
- Visualisation claire avec bounding boxes, IDs, et zones d'alerte.

### Cas d'usage concrets

1.  **S√©curit√© B√¢timent** : D√©tecter une personne entrant par la sortie de secours.
2.  **Retail (Magasin)** : Analyser le parcours client (Heatmap) et le temps pass√© en rayon.
3.  **Gestion de foule** : Compter le nombre de personnes uniques dans un √©v√©nement.

---

## 5. Limitations & Am√©liorations Futures üöÄ

Il faut √™tre honn√™te sur les limites pour montrer votre recul critique.

- **Temps R√©el** : Actuellement, le syst√®me traite les vid√©os en diff√©r√© (offline) pour maximiser la pr√©cision. Une optimisation (TensorRT, quantization) serait n√©cessaire pour du vrai temps r√©el √† 30 FPS.
- **Re-ID Difficile** : Si une personne change de v√™tements (peu probable en 10min) ou si l'angle de vue est drastiquement diff√©rent (vue de dessus vs vue de face), le Re-ID peut √©chouer.
- **Hardware** : Le syst√®me d√©pend de la puissance GPU pour √™tre rapide.

---

## 6. Conclusion

Ce projet d√©montre comment l'assemblage de briques technologiques modernes (YOLO, DeepSORT, ResNet) permet de cr√©er un syst√®me de surveillance de niveau industriel, capable de transformer une simple vid√©o en intelligence actionnable.
